---
layout: post
title: The next generation model should be ambidextrous
---

I think this is worthy of being GPT-5.
I won't be surprised if this is called GPT-4a (a for ambidextrous) or GPT-4m (m for multichannel) though.



## Think of how you converse

If humans hold conversations like the current chatbot that is made of alternative user assistant pairs
- You only consume words
- You do not interrupt the other person at all
- You need to wait for the other person to stop before you start thinking
- You start talking after you finish thinking
- You only produce words

We don't converse like how the current chatbots do.

This is what humans do
- You look at body language of the person talking
- You could interrupt the person if appropriate
- While the other person is talking, you are thinking
- You present gestures or certain body language
- You words has a certain emphasis or tone
- While you are talking, you (should) read the facial expression of your audiences
- You may be multitasking - for example walking up the stairs, eating food

We should train models that should at least be able to converse like humans.
The model should be multichannel.



## Difference between Omnimodality and Multichannel

GPT-4o introduced omnimodality (the 'o' in 4o).

It was claimed that 

Multichannel here refers to preceving and producing tokens of multiple channels at the same time.
The tokens may be of the same or different modality.




When you talk to someone, you don't get 

When it is appropriate, you interrupt them.

When you listen, you should be thinking of something as well - what to ask next, how to respond.

But humans do not do this.

You don't actually talk to someone.

You need think 


## Architecture

I think the architecture will be very similar to the standard decoder architecture.

Instead of one stream of inputs

You can have the model to wind-up and wind-down on demand.


## Think of how humans are ambidextrous


## Everything could still be modelled as a next token prediction



## Robotics


## Training

Imitation learning

The chain of thought is mostly synthetic data and we could train on it.



## Inference

Reading might not be easily parallelizable anymore?





## Consciousness

In this definition, consciousness is the ability to produce interpretable tokens that the model itself could interpret.


## Signs

OpenAI response API







The environment is a sampler


Omnichannel etc
You think while you speak
You interpret what people say while you speak



When I was in undergrad I was informed - (cite Ilya's video) - if you can predict the next token, you understand.

Next token prediction could be a lot of things. Jason Wei's slides?

When you write the first token you already somewhat planned what to do at the end.

Some tokens are easier than the others

Everything can be formulated as next token prediction (as long as the output is next)

Diffusion?
Image generation?
Voice?

Large concept models?

At this point it is somewhat of a ___
"Everything follow the law of Physics"
"God has a plan for everything"
If it doesn't you just redefine your task


You can train a model to predict the next prime number of a large prime number, but this does not mean you should.
You should still train the model to either use tools to calculate, or use reasoning to calculate by hand.





