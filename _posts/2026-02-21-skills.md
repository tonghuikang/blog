---
layout: post
title: Writing skills for the company
---

Agent [Skills](https://agentskills.io/home) are folders of instructions, scripts, and resources that agents can discover and use to do things more accurately and efficiently.

I think the skills abstraction is great.
The principle of progressive disclosure allows us to load only the tokens that are needed.
It is now the standardized format to store AI instructions that I was looking for.
Supporting agent skills is already a baseline expectation of all AI coding tools.

I want to encourage my colleagues to write and maintain skills to accelerate their work.
I describe how I am doing it.


## What exactly are skills?

Skills consist of three elements at minimum:
- Skill name
- Skill description
- Skill content

This is one example.

```
---
name: write-commit-message
description: Commit message guidelines. Use when writing git commit messages.
---

<skill content>
```

When the AI coding tool starts a session, it will load to the model context the skill name and skill description.

This is what you see in Claude Code when you run `/context`

```
Skills · /skills

Project
└ write-commit-message: 21 tokens
```

When the model decides to invoke a skill, it will read the skill content.
In this case, the skill content contains information on how to write commit messages.


## Why do we need skills?

Skills are needed to instruct the model on how to do things more accurately and efficiently.

I will use the write commit message skill as an example here.
The company likely has some standards on what the commit message should contain.

For example, the commit message should contain this information:
- How to write the commit title
- What to include in the commit description (context, design decisions, test plan)
- What not to include in the commit description
- Who the reviewers are
- What URLs need to be included (for example Slack, Asana)

It is true that a well-trained model should figure out these requirements by looking at similar commits, or running the unit tests related to the commit message.
There are also quality requirements that could only be inferred after looking at tens of commits.

However, no matter how well trained the model is, they will need to spend tokens to figure out the standards.
You can see that this thing could have been done more accurately and efficiently.

Instead of having the AI inefficiently and likely inaccurately figure out the commit message standards in every session, the skill file documents the commit message standards, and the AI could skip the entire process of looking at many commit messages and failing unit tests.

Initially I have been placing the commit message standards in CLAUDE.md / AGENTS.md. This was a reasonable place to put the instruction because it is globally relevant. I have been asking CLAUDE.md to only include [globally](https://blog.huikang.dev/2025/05/31/writing-claude-md.html) relevant information. Even as writing commit messages is global, this also means that the commit message instructions will be loaded even if the user is not writing a commit message, for example when asking questions about the codebase.

Then I moved the commit message standards to the git commit template. Instead of placing instructions in CLAUDE.md, CLAUDE.md could have an instruction that points to the git commit template. This is what I have been doing before we have skills. This still follows the progressive disclosure principle, because I load the commit message standards only when I write the commit message.

Even though placing the commit message standards in the git commit template fulfills the principle of progressive disclosure, there is still benefit of making `write-commit-message` a skill. We want to centralize our AI instructions instead of scattering them over the codebase. When we implement telemetry and feedback loops for skills, `write-commit-message` can also benefit if it is a skill.



## When you should write a skill

If you want a process to be done more efficiently and rigorously with AI tools, you should write a skill. These are some examples where you should think about writing a skill.

You have a resource that you want to provide access to your AI. The resource could be Notion, Slack, Asana, or any internal pages. Instead of playing telephone between the AI coding tool and the resource, you can write a skill that teaches AI how to read the resource. However, there is a prerequisite - this assumes that your AI coding tool has access to the resources, and you will have to get that set up first.

You have repetitive processes that you want automated. For example, every day I am supposed to check the feed statistics for our recommendation system. This involves looking at dashes. If there are significant movements in speed, I need to explain it by looking at commit logs. This should have been a skill.

You want a process to be done more efficiently in the future. One of such process is oncall pages. You might already be handling oncall pages with AI tools that have access to dashes and error logs. In the future, you want to handle this more efficiently. You can write a skill that informs the model of the resources that they should look at and the dead ends that they should be aware of.



There are cases where you should not write a skill.

- Tasks that the AI could already solve perfectly. For example, you might want to consider adding a skill on how to write unit tests. Even though it might feel good to see skills being activated, it might not mean that it is effective.
- Features that the AI coding tool should already be good at. There should not be a `plan-mode` or `clarify-user-questions` skill because AI coding tools should already be shipped with this in their system prompt.
- Workflows that should have been a deterministic script. If I am writing a `check-commit-message` skill, I should not be asking the model to run checks where it could have been unit tests. The LLM should not be an expensive linter. If there is still value in writing `check-commit-message` to check the qualitative aspects of the commit message, the skill should ask the model to run the relevant unit tests for the deterministic checks.


## Skill writing advice

You should think of the simplest skill that you can write.

You could look at what you did in the past week and think of

- The documents that you need to repeatedly write or review
- Questions that you need to repeatedly answer
- Investigations that you need to repeat

Even though the skill standard allows for supplementary files, you should start simple with a single SKILL.md.

You should test your skill.
When you commit your skill, you should include the evidence that it is tested.
Unlike unit tests, testing a skill is not deterministic.
However, you should still test and provide evidence of testing.

These are some ways I think are good evidence of testing:

- If the skill output is a document, the resulting document could be evidence.
- If the skill provides instructions on how to read a resource, you could start a new session to see whether the model could invoke the skill and read the resource without tripping over issues.
- If the skill helps with an investigation, the investigation thread could be evidence.



## Managing skills for the company

As you get your hundred colleagues to commit their skills into the codebase, you will soon have hundreds of skills.

This means that you will have hundreds of skill names, and hundreds of skill descriptions. If each skill is 50 tokens, this will be 5000 tokens. Also depending on the quality of your skill descriptions, the model might invoke skills unnecessarily, or fail to invoke skills when it is needed.

If you look at the skills, there are skills that are company-wide and there are skills that are team-wide. We should only load company-wide skills into context.

This can be done in Claude Code. For team-wide skills, I can add `disable-model-invocation: true` to prevent the skill from being loaded in context.

```
---
name: investigate-speed-feed
description: 
disable-model-invocation: true
---

<skill content>

```

This will mean that if I go to Claude Code and ask "please investigate feed speed", the skill will not be invoked. I need to write `/investigate-speed-feed`. This is fine, because people who need to use the skill should know about the skill.

By separating team-wide skills and company-wide skills, and require all team-wide skills to have model invocation disabled, I reduce the risk of AI not invoking necessary skills or invoking unnecessary skills.

Notice that I say "team-wide skills" and "company-wide skills". The field name is `disable-model-invocation: true`, which unfortunately is a negative. It could have been "invokable skills" or "non-invokable skills", but it is confusing because users can invoke a skill with the slash command. The more precise term is "model-invokable skills" and "non-model-invokable skills" but that is too long. I am glad that I have arrived with the terms "team-wide skills" and "company-wide skills".

I organize the team-wide skills and company-wide skills into two folders.

```
skills/
     ├── company_wide/
     │   └── write-commit-message/
     │       └── SKILL.md
     └── team_wide/
         └── investigate-speed-feed/
             └── SKILL.md
```

However, the skill standard requires all skills to be at the same level.

So I have every skill folder be a soft symlink to skills/all.

```
skills/
     ├── all/
     ├── company_wide/
     └── team_wide/
```

`.claude/skills`, `.cursor/skills` and `.codex/skills` are soft symlinks to `skills/all`.


I hope this helps you write skills for your company, so that the agents could do things more accurately and efficiently.


